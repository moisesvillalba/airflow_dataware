[core]
# Directorio donde se almacenan los DAGs
dags_folder = /opt/airflow/dags

# Directorio donde se almacenan los logs de Airflow
base_log_folder = /opt/airflow/logs

# Cadena de conexión a la base de datos PostgreSQL
sql_alchemy_conn = postgresql+psycopg2://airflow:airflow@postgres:5432/airflow

# Si se deben cargar ejemplos de DAGs
load_examples = False

# Directorio donde se almacenan los plugins de Airflow
plugins_folder = /opt/airflow/plugins

# Configuración para el almacenamiento en caché de las conexiones a la base de datos
sql_alchemy_pool_size = 5
sql_alchemy_max_overflow = 10

[webserver]
# Puerto en el que el servidor web de Airflow escuchará
web_server_port = 8080

# URL base para acceder a la interfaz web de Airflow
base_url = http://localhost:8080

[logging]
# Nivel de logging para Airflow
logging_level = INFO

[worker]
# Número de procesos concurrentes para los workers
worker_concurrency = 16

[scheduler]
# Intervalo en segundos para revisar nuevos DAGs en el directorio
scheduler.dag_dir_list_interval = 300

[celery]
# URL del broker para Celery, en este caso usando Redis
broker_url = redis://localhost:6379/0

# Backend para almacenar los resultados de las tareas de Celery
result_backend = postgresql+psycopg2://airflow:airflow@postgres:5432/airflow

[openlineage]
# Configuración para OpenLineage, si es necesario
disabled = True
